{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhrW0WCPgq_H",
        "outputId": "1ba225b1-05f7-443d-e357-35665a77e964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.89-py3-none-any.whl (561 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0+cu118)\n",
            "Collecting sentry-sdk\n",
            "  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.1+cu118)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: sentry-sdk, thop, ultralytics\n",
            "Successfully installed sentry-sdk-1.21.1 thop-0.1.1.post2209072238 ultralytics-8.0.89\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QXCrKLt1gs1J"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9UjePV5g5M-",
        "outputId": "e2742190-24db-4558-cbac-cee12cd8c7da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PRO TIP ðŸ’¡ Replace 'model=yolov5l.pt' with new 'model=yolov5lu.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov5lu.pt to yolov5lu.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102M/102M [00:03<00:00, 35.2MB/s] \n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov5l.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ykLGISWMg-71"
      },
      "outputs": [],
      "source": [
        "!touch data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv9PXHrchXfX",
        "outputId": "81d58e07-ae36-4606-ca5e-206c90adf499"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.89 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5l.pt, data=/content/data.yaml, epochs=25, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 15.0MB/s]\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      7040  ultralytics.nn.modules.Conv                  [3, 64, 6, 2, 2]              \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  2                  -1  3    156928  ultralytics.nn.modules.C3                    [128, 128, 3]                 \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  4                  -1  6   1118208  ultralytics.nn.modules.C3                    [256, 256, 6]                 \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  6                  -1  9   6433792  ultralytics.nn.modules.C3                    [512, 512, 9]                 \n",
            "  7                  -1  1   4720640  ultralytics.nn.modules.Conv                  [512, 1024, 3, 2]             \n",
            "  8                  -1  3   9971712  ultralytics.nn.modules.C3                    [1024, 1024, 3]               \n",
            "  9                  -1  1   2624512  ultralytics.nn.modules.SPPF                  [1024, 1024, 5]               \n",
            " 10                  -1  1    525312  ultralytics.nn.modules.Conv                  [1024, 512, 1, 1]             \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 13                  -1  3   2757632  ultralytics.nn.modules.C3                    [1024, 512, 3, False]         \n",
            " 14                  -1  1    131584  ultralytics.nn.modules.Conv                  [512, 256, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 17                  -1  3    690688  ultralytics.nn.modules.C3                    [512, 256, 3, False]          \n",
            " 18                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 20                  -1  3   2495488  ultralytics.nn.modules.C3                    [512, 512, 3, False]          \n",
            " 21                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 23                  -1  3   9971712  ultralytics.nn.modules.C3                    [1024, 1024, 3, False]        \n",
            " 24        [17, 20, 23]  1   7065070  ultralytics.nn.modules.Detect                [10, [256, 512, 1024]]        \n",
            "YOLOv5l summary: 416 layers, 53171054 parameters, 53171038 gradients, 135.3 GFLOPs\n",
            "\n",
            "Transferred 685/691 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 27.8MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/all_data/train/labels.cache... 186 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/all_data/valid/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/25      10.4G      1.576      3.735      1.939         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:24<00:00,  2.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.93s/it]\n",
            "                   all         31         54       0.57      0.369       0.41      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/25      10.6G      1.446      2.448      1.819         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
            "                   all         31         54      0.854      0.601      0.669       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/25      10.6G      1.244      1.909      1.614         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all         31         54      0.776      0.607      0.694      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/25      10.6G      1.188      1.723      1.561         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all         31         54      0.726      0.783      0.776      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/25      10.6G      1.097      1.399      1.477         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]\n",
            "                   all         31         54      0.864      0.622      0.824      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/25      10.6G      1.076      1.296      1.427         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.17s/it]\n",
            "                   all         31         54      0.551      0.749      0.744      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/25      10.6G      1.058      1.194      1.376         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all         31         54      0.652       0.68      0.732       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/25      10.6G       1.08      1.218       1.37         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all         31         54      0.721      0.603      0.734      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/25      10.6G      1.076      1.075      1.359         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         31         54      0.656      0.535      0.629      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/25      10.6G      1.041      1.084      1.373         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         31         54      0.598      0.575      0.581      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/25      10.6G       1.01      1.069      1.346         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.27s/it]\n",
            "                   all         31         54       0.74      0.474      0.619      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/25      10.6G     0.9851      1.014      1.353         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all         31         54      0.689      0.671      0.732      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/25      10.6G       1.04     0.9591      1.336         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all         31         54      0.763      0.654      0.707      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/25      10.6G          1     0.9048      1.348         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.14it/s]\n",
            "                   all         31         54      0.534      0.565      0.562      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/25      10.6G     0.9074     0.8491      1.252         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.16it/s]\n",
            "                   all         31         54      0.595      0.503      0.583      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/25      10.6G     0.9063     0.8401      1.279         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.15s/it]\n",
            "                   all         31         54      0.414       0.59      0.587      0.354\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/25      10.6G     0.8603     0.7874      1.255         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]\n",
            "                   all         31         54      0.696      0.617      0.627      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/25      10.6G     0.8459     0.7702      1.254         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all         31         54      0.813      0.594      0.708      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/25      10.6G     0.8276     0.6846      1.225         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.10it/s]\n",
            "                   all         31         54      0.858      0.504      0.621       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/25      10.6G     0.7827     0.6951       1.19         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.10it/s]\n",
            "                   all         31         54      0.792      0.593      0.694      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/25      10.6G     0.8149     0.6649      1.207         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.01s/it]\n",
            "                   all         31         54      0.822      0.676      0.755      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/25      10.6G     0.7485     0.6517      1.161         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.12s/it]\n",
            "                   all         31         54       0.79      0.664      0.742      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/25      10.6G     0.7317     0.6443      1.167         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         31         54      0.906      0.651      0.769      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/25      10.6G     0.6955     0.5737      1.137         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
            "                   all         31         54       0.91      0.658      0.755      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/25      10.6G     0.6715     0.5705      1.132         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all         31         54      0.934      0.686      0.763      0.498\n",
            "\n",
            "25 epochs completed in 0.090 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 106.8MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 106.8MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.89 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv5l summary (fused): 303 layers, 53139118 parameters, 0 gradients, 134.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]\n",
            "                   all         31         54      0.864      0.622      0.824      0.527\n",
            "                  book         31          4       0.28       0.75      0.822      0.482\n",
            "                bottle         31          5      0.841        0.4      0.402        0.3\n",
            "                   cup         31          4      0.913       0.75       0.87      0.612\n",
            "               glasses         31          2          1          0       0.51      0.354\n",
            "              keyboard         31          4      0.862          1      0.995      0.771\n",
            "                  lock         31          2      0.959          1      0.995      0.598\n",
            "                   pen         31         10          1      0.496      0.676      0.349\n",
            "                person         31         17      0.964      0.824      0.977      0.684\n",
            "            smartphone         31          4      0.822          1      0.995      0.796\n",
            "                 watch         31          2          1          0      0.995      0.324\n",
            "Speed: 0.2ms preprocess, 15.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model.train(data=\"/content/data.yaml\" , epochs = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sV3a-MPIhkI1"
      },
      "outputs": [],
      "source": [
        "infer = YOLO(\"/content/runs/detect/train/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfFo7OeXnnMK",
        "outputId": "70d02fed-9fe1-47b9-df17-ae074dc3b87a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/16 /content/drive/MyDrive/all_data/test/images/19_jpg.rf.597c50f86b5c68d4cc0859baea2a5e1f.jpg: 640x640 1 smartphone, 59.2ms\n",
            "image 2/16 /content/drive/MyDrive/all_data/test/images/2_jpg.rf.6cdd9d1c71eacf06edea1b180169523d.jpg: 640x640 1 smartphone, 58.4ms\n",
            "image 3/16 /content/drive/MyDrive/all_data/test/images/6_jpg.rf.7f8d0836050ab336b1ee028147eb5926.jpg: 640x640 1 smartphone, 58.3ms\n",
            "image 4/16 /content/drive/MyDrive/all_data/test/images/b11_jpg.rf.00123ba78c37f00c718129cc8a66930c.jpg: 640x640 (no detections), 58.7ms\n",
            "image 5/16 /content/drive/MyDrive/all_data/test/images/bot1_jpg.rf.f16b7c27b31b3834608950f5c1a6b44e.jpg: 640x640 1 bottle, 58.5ms\n",
            "image 6/16 /content/drive/MyDrive/all_data/test/images/bot7_jpg.rf.3da701b7223d3dc4efaa9a1951eeab53.jpg: 640x640 1 bottle, 1 pen, 58.5ms\n",
            "image 7/16 /content/drive/MyDrive/all_data/test/images/c1_jpg.rf.6a810d259d761e328e9a21c073d1aee8.jpg: 640x640 1 cup, 58.7ms\n",
            "image 8/16 /content/drive/MyDrive/all_data/test/images/c2_jpg.rf.cdf63267fc515d07e1131f524603e907.jpg: 640x640 1 cup, 59.9ms\n",
            "image 9/16 /content/drive/MyDrive/all_data/test/images/c9_jpg.rf.b65dae030f60f0fe6794006372391c8c.jpg: 640x640 1 smartphone, 60.1ms\n",
            "image 10/16 /content/drive/MyDrive/all_data/test/images/p16_jpg.rf.ed68c55cb40ee3fde7c5be6ee6397f25.jpg: 640x640 1 person, 58.6ms\n",
            "image 11/16 /content/drive/MyDrive/all_data/test/images/p17_jpg.rf.f6b55c6ef43ac2ab295f7056a1956c86.jpg: 640x640 1 person, 58.4ms\n",
            "image 12/16 /content/drive/MyDrive/all_data/test/images/p24_jpg.rf.6673d6f98dc7183b869a53be3a8cc00b.jpg: 640x640 2 persons, 58.6ms\n",
            "image 13/16 /content/drive/MyDrive/all_data/test/images/p28_jpg.rf.d850f345c555a878078d046bc6a014cc.jpg: 640x640 4 persons, 58.6ms\n",
            "image 14/16 /content/drive/MyDrive/all_data/test/images/p8_jpg.rf.0704f4dd7b0ec7a03ae271d4a3800d23.jpg: 640x640 1 person, 58.3ms\n",
            "image 15/16 /content/drive/MyDrive/all_data/test/images/pen17_jpg.rf.b3192e012f273939dbe8937aefbe8f12.jpg: 640x640 1 book, 1 pen, 58.3ms\n",
            "image 16/16 /content/drive/MyDrive/all_data/test/images/w3_jpg.rf.17144b2e19c862bfa26843523c374c83.jpg: 640x640 (no detections), 58.3ms\n",
            "Speed: 1.7ms preprocess, 58.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "19 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[ 39,  42,  70],\n",
              "         [ 38,  41,  69],\n",
              "         [ 38,  41,  69],\n",
              "         ...,\n",
              "         [204, 242, 246],\n",
              "         [205, 243, 247],\n",
              "         [205, 243, 247]],\n",
              " \n",
              "        [[ 39,  42,  70],\n",
              "         [ 39,  42,  70],\n",
              "         [ 38,  41,  69],\n",
              "         ...,\n",
              "         [207, 245, 249],\n",
              "         [207, 245, 249],\n",
              "         [207, 245, 249]],\n",
              " \n",
              "        [[ 40,  43,  71],\n",
              "         [ 39,  42,  70],\n",
              "         [ 38,  41,  69],\n",
              "         ...,\n",
              "         [210, 247, 251],\n",
              "         [211, 248, 252],\n",
              "         [211, 248, 252]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[249, 224, 204],\n",
              "         [249, 224, 204],\n",
              "         [249, 224, 204],\n",
              "         ...,\n",
              "         [149, 169, 200],\n",
              "         [148, 168, 199],\n",
              "         [147, 167, 198]],\n",
              " \n",
              "        [[249, 224, 204],\n",
              "         [249, 224, 204],\n",
              "         [249, 224, 204],\n",
              "         ...,\n",
              "         [149, 169, 200],\n",
              "         [148, 168, 199],\n",
              "         [148, 168, 199]],\n",
              " \n",
              "        [[249, 224, 204],\n",
              "         [249, 224, 204],\n",
              "         [249, 224, 204],\n",
              "         ...,\n",
              "         [149, 169, 200],\n",
              "         [149, 169, 200],\n",
              "         [148, 168, 199]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/19_jpg.rf.597c50f86b5c68d4cc0859baea2a5e1f.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.8763542175292969, 'inference': 59.23342704772949, 'postprocess': 1.8758773803710938},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[184, 184, 178],\n",
              "         [185, 185, 179],\n",
              "         [187, 187, 181],\n",
              "         ...,\n",
              "         [206, 196, 186],\n",
              "         [206, 196, 186],\n",
              "         [206, 196, 186]],\n",
              " \n",
              "        [[185, 185, 179],\n",
              "         [186, 186, 180],\n",
              "         [187, 187, 181],\n",
              "         ...,\n",
              "         [206, 196, 186],\n",
              "         [206, 196, 186],\n",
              "         [206, 196, 186]],\n",
              " \n",
              "        [[185, 185, 179],\n",
              "         [186, 186, 180],\n",
              "         [187, 187, 181],\n",
              "         ...,\n",
              "         [206, 196, 186],\n",
              "         [206, 196, 186],\n",
              "         [206, 196, 186]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[168, 169, 160],\n",
              "         [167, 168, 159],\n",
              "         [167, 168, 159],\n",
              "         ...,\n",
              "         [183, 170, 156],\n",
              "         [183, 170, 156],\n",
              "         [183, 170, 156]],\n",
              " \n",
              "        [[168, 169, 160],\n",
              "         [167, 168, 159],\n",
              "         [167, 168, 159],\n",
              "         ...,\n",
              "         [183, 170, 156],\n",
              "         [183, 170, 156],\n",
              "         [183, 170, 156]],\n",
              " \n",
              "        [[168, 169, 160],\n",
              "         [167, 168, 159],\n",
              "         [167, 168, 159],\n",
              "         ...,\n",
              "         [183, 170, 156],\n",
              "         [183, 170, 156],\n",
              "         [183, 170, 156]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/2_jpg.rf.6cdd9d1c71eacf06edea1b180169523d.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.623392105102539, 'inference': 58.38370323181152, 'postprocess': 1.8279552459716797},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[201, 185, 169],\n",
              "         [199, 182, 163],\n",
              "         [199, 176, 154],\n",
              "         ...,\n",
              "         [ 29,  36,  51],\n",
              "         [ 31,  36,  51],\n",
              "         [ 30,  35,  50]],\n",
              " \n",
              "        [[201, 182, 167],\n",
              "         [197, 177, 159],\n",
              "         [192, 170, 145],\n",
              "         ...,\n",
              "         [ 29,  36,  51],\n",
              "         [ 31,  36,  51],\n",
              "         [ 30,  35,  50]],\n",
              " \n",
              "        [[201, 181, 164],\n",
              "         [198, 177, 156],\n",
              "         [187, 163, 139],\n",
              "         ...,\n",
              "         [ 29,  36,  51],\n",
              "         [ 31,  36,  51],\n",
              "         [ 30,  35,  50]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[195, 183, 177],\n",
              "         [195, 183, 177],\n",
              "         [195, 183, 177],\n",
              "         ...,\n",
              "         [175, 165, 158],\n",
              "         [175, 165, 158],\n",
              "         [174, 164, 157]],\n",
              " \n",
              "        [[195, 183, 177],\n",
              "         [195, 183, 177],\n",
              "         [195, 183, 177],\n",
              "         ...,\n",
              "         [175, 165, 158],\n",
              "         [174, 164, 157],\n",
              "         [174, 164, 157]],\n",
              " \n",
              "        [[195, 183, 177],\n",
              "         [195, 183, 177],\n",
              "         [195, 183, 177],\n",
              "         ...,\n",
              "         [174, 164, 157],\n",
              "         [174, 164, 157],\n",
              "         [174, 164, 157]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/6_jpg.rf.7f8d0836050ab336b1ee028147eb5926.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.6193389892578125, 'inference': 58.278560638427734, 'postprocess': 1.8239021301269531},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[172, 155, 104],\n",
              "         [171, 154, 103],\n",
              "         [168, 151, 100],\n",
              "         ...,\n",
              "         [196, 191, 193],\n",
              "         [196, 190, 195],\n",
              "         [196, 190, 195]],\n",
              " \n",
              "        [[170, 153, 102],\n",
              "         [169, 152, 101],\n",
              "         [167, 150,  99],\n",
              "         ...,\n",
              "         [196, 191, 193],\n",
              "         [196, 190, 195],\n",
              "         [196, 190, 195]],\n",
              " \n",
              "        [[168, 151, 100],\n",
              "         [167, 150,  99],\n",
              "         [165, 148,  97],\n",
              "         ...,\n",
              "         [196, 191, 193],\n",
              "         [196, 190, 195],\n",
              "         [196, 190, 195]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 24,  16,   0],\n",
              "         [ 24,  16,   0],\n",
              "         [ 24,  16,   0],\n",
              "         ...,\n",
              "         [ 30,  15,   0],\n",
              "         [ 30,  15,   0],\n",
              "         [ 30,  15,   0]],\n",
              " \n",
              "        [[ 24,  16,   0],\n",
              "         [ 24,  16,   0],\n",
              "         [ 23,  16,   0],\n",
              "         ...,\n",
              "         [ 30,  15,   0],\n",
              "         [ 30,  15,   0],\n",
              "         [ 30,  15,   0]],\n",
              " \n",
              "        [[ 24,  16,   0],\n",
              "         [ 24,  16,   0],\n",
              "         [ 23,  16,   0],\n",
              "         ...,\n",
              "         [ 30,  15,   0],\n",
              "         [ 30,  15,   0],\n",
              "         [ 30,  15,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/b11_jpg.rf.00123ba78c37f00c718129cc8a66930c.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.590728759765625, 'inference': 58.73680114746094, 'postprocess': 2.2339820861816406},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[244, 242, 242],\n",
              "         [244, 242, 242],\n",
              "         [244, 242, 242],\n",
              "         ...,\n",
              "         [252, 250, 249],\n",
              "         [252, 250, 249],\n",
              "         [252, 250, 249]],\n",
              " \n",
              "        [[244, 242, 242],\n",
              "         [244, 242, 242],\n",
              "         [244, 242, 242],\n",
              "         ...,\n",
              "         [252, 250, 249],\n",
              "         [252, 250, 249],\n",
              "         [252, 250, 249]],\n",
              " \n",
              "        [[244, 242, 242],\n",
              "         [244, 242, 242],\n",
              "         [244, 242, 242],\n",
              "         ...,\n",
              "         [252, 250, 249],\n",
              "         [252, 250, 249],\n",
              "         [252, 250, 249]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[241, 232, 228],\n",
              "         [241, 232, 228],\n",
              "         [241, 232, 228],\n",
              "         ...,\n",
              "         [251, 242, 238],\n",
              "         [251, 242, 238],\n",
              "         [251, 242, 238]],\n",
              " \n",
              "        [[241, 232, 228],\n",
              "         [241, 232, 228],\n",
              "         [241, 232, 228],\n",
              "         ...,\n",
              "         [251, 242, 238],\n",
              "         [251, 242, 238],\n",
              "         [251, 242, 238]],\n",
              " \n",
              "        [[241, 232, 228],\n",
              "         [241, 232, 228],\n",
              "         [241, 232, 228],\n",
              "         ...,\n",
              "         [251, 242, 238],\n",
              "         [251, 242, 238],\n",
              "         [251, 242, 238]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/bot1_jpg.rf.f16b7c27b31b3834608950f5c1a6b44e.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.6019344329833984, 'inference': 58.49885940551758, 'postprocess': 1.8880367279052734},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[148, 147, 151],\n",
              "         [148, 147, 151],\n",
              "         [147, 146, 150],\n",
              "         ...,\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21]],\n",
              " \n",
              "        [[155, 154, 158],\n",
              "         [155, 154, 158],\n",
              "         [154, 153, 157],\n",
              "         ...,\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21]],\n",
              " \n",
              "        [[161, 160, 164],\n",
              "         [161, 160, 164],\n",
              "         [159, 158, 162],\n",
              "         ...,\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[135, 119, 113],\n",
              "         [136, 120, 114],\n",
              "         [136, 120, 114],\n",
              "         ...,\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21]],\n",
              " \n",
              "        [[134, 118, 112],\n",
              "         [134, 118, 112],\n",
              "         [135, 119, 113],\n",
              "         ...,\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21]],\n",
              " \n",
              "        [[133, 117, 111],\n",
              "         [134, 118, 112],\n",
              "         [134, 118, 112],\n",
              "         ...,\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21],\n",
              "         [ 30,  26,  21]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/bot7_jpg.rf.3da701b7223d3dc4efaa9a1951eeab53.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.638174057006836, 'inference': 58.5479736328125, 'postprocess': 1.9829273223876953},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[219, 221, 221],\n",
              "         [219, 221, 221],\n",
              "         [220, 222, 222],\n",
              "         ...,\n",
              "         [204, 202, 202],\n",
              "         [204, 202, 202],\n",
              "         [204, 202, 202]],\n",
              " \n",
              "        [[219, 221, 221],\n",
              "         [219, 221, 221],\n",
              "         [220, 222, 222],\n",
              "         ...,\n",
              "         [205, 203, 203],\n",
              "         [204, 202, 202],\n",
              "         [204, 202, 202]],\n",
              " \n",
              "        [[219, 221, 221],\n",
              "         [219, 221, 221],\n",
              "         [220, 222, 222],\n",
              "         ...,\n",
              "         [205, 203, 203],\n",
              "         [205, 203, 203],\n",
              "         [204, 202, 202]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         ...,\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227]],\n",
              " \n",
              "        [[251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         ...,\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227]],\n",
              " \n",
              "        [[251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         ...,\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/c1_jpg.rf.6a810d259d761e328e9a21c073d1aee8.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.6226768493652344, 'inference': 58.734893798828125, 'postprocess': 3.4787654876708984},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[184, 165, 150],\n",
              "         [185, 166, 151],\n",
              "         [187, 167, 150],\n",
              "         ...,\n",
              "         [151, 117,  93],\n",
              "         [144, 109,  89],\n",
              "         [139, 104,  84]],\n",
              " \n",
              "        [[169, 149, 132],\n",
              "         [170, 150, 133],\n",
              "         [174, 151, 135],\n",
              "         ...,\n",
              "         [155, 121,  97],\n",
              "         [148, 113,  93],\n",
              "         [143, 108,  88]],\n",
              " \n",
              "        [[165, 143, 125],\n",
              "         [166, 145, 124],\n",
              "         [171, 147, 127],\n",
              "         ...,\n",
              "         [157, 123,  99],\n",
              "         [150, 115,  95],\n",
              "         [145, 110,  90]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[191, 154, 128],\n",
              "         [190, 153, 127],\n",
              "         [189, 152, 126],\n",
              "         ...,\n",
              "         [191, 152, 124],\n",
              "         [188, 149, 121],\n",
              "         [182, 143, 115]],\n",
              " \n",
              "        [[191, 154, 128],\n",
              "         [190, 153, 127],\n",
              "         [189, 152, 126],\n",
              "         ...,\n",
              "         [192, 153, 125],\n",
              "         [189, 150, 122],\n",
              "         [183, 144, 116]],\n",
              " \n",
              "        [[191, 154, 128],\n",
              "         [190, 153, 127],\n",
              "         [189, 152, 126],\n",
              "         ...,\n",
              "         [193, 154, 126],\n",
              "         [190, 151, 123],\n",
              "         [184, 145, 117]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/c2_jpg.rf.cdf63267fc515d07e1131f524603e907.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.939535140991211, 'inference': 59.945106506347656, 'postprocess': 2.319812774658203},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[ 51, 100, 132],\n",
              "         [ 43,  90, 121],\n",
              "         [ 35,  79, 110],\n",
              "         ...,\n",
              "         [ 67,  54,  40],\n",
              "         [106,  93,  79],\n",
              "         [ 57,  44,  30]],\n",
              " \n",
              "        [[ 63, 112, 144],\n",
              "         [ 54, 101, 133],\n",
              "         [ 45,  89, 120],\n",
              "         ...,\n",
              "         [ 60,  47,  33],\n",
              "         [ 84,  71,  57],\n",
              "         [ 63,  50,  36]],\n",
              " \n",
              "        [[ 72, 123, 156],\n",
              "         [ 64, 113, 145],\n",
              "         [ 54, 100, 131],\n",
              "         ...,\n",
              "         [ 61,  48,  34],\n",
              "         [ 69,  56,  42],\n",
              "         [ 68,  55,  41]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[155, 127, 110],\n",
              "         [161, 133, 116],\n",
              "         [163, 135, 118],\n",
              "         ...,\n",
              "         [ 32,  20,  10],\n",
              "         [ 37,  25,  15],\n",
              "         [ 53,  41,  31]],\n",
              " \n",
              "        [[154, 126, 109],\n",
              "         [156, 128, 111],\n",
              "         [161, 133, 116],\n",
              "         ...,\n",
              "         [ 69,  52,  43],\n",
              "         [ 59,  42,  33],\n",
              "         [ 57,  40,  31]],\n",
              " \n",
              "        [[155, 127, 110],\n",
              "         [153, 125, 108],\n",
              "         [158, 130, 113],\n",
              "         ...,\n",
              "         [ 70,  51,  43],\n",
              "         [ 63,  44,  36],\n",
              "         [ 72,  53,  45]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/c9_jpg.rf.b65dae030f60f0fe6794006372391c8c.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.7986297607421875, 'inference': 60.12248992919922, 'postprocess': 2.2819042205810547},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[56, 57, 61],\n",
              "         [56, 57, 61],\n",
              "         [56, 57, 61],\n",
              "         ...,\n",
              "         [43, 45, 56],\n",
              "         [41, 43, 54],\n",
              "         [41, 43, 54]],\n",
              " \n",
              "        [[55, 56, 60],\n",
              "         [55, 56, 60],\n",
              "         [55, 56, 60],\n",
              "         ...,\n",
              "         [43, 45, 56],\n",
              "         [41, 43, 54],\n",
              "         [41, 43, 54]],\n",
              " \n",
              "        [[54, 55, 59],\n",
              "         [54, 55, 59],\n",
              "         [54, 55, 59],\n",
              "         ...,\n",
              "         [43, 45, 56],\n",
              "         [41, 43, 54],\n",
              "         [41, 43, 54]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[15, 15, 21],\n",
              "         [15, 15, 21],\n",
              "         [15, 15, 21],\n",
              "         ...,\n",
              "         [10, 13, 18],\n",
              "         [10, 13, 18],\n",
              "         [10, 13, 18]],\n",
              " \n",
              "        [[15, 15, 21],\n",
              "         [15, 15, 21],\n",
              "         [15, 15, 21],\n",
              "         ...,\n",
              "         [ 9, 12, 17],\n",
              "         [ 9, 12, 17],\n",
              "         [ 9, 12, 17]],\n",
              " \n",
              "        [[15, 15, 21],\n",
              "         [15, 15, 21],\n",
              "         [15, 15, 21],\n",
              "         ...,\n",
              "         [ 9, 12, 17],\n",
              "         [ 9, 12, 17],\n",
              "         [ 9, 12, 17]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/p16_jpg.rf.ed68c55cb40ee3fde7c5be6ee6397f25.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.8606185913085938, 'inference': 58.550357818603516, 'postprocess': 2.2420883178710938},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[166, 182, 194],\n",
              "         [165, 181, 193],\n",
              "         [164, 180, 192],\n",
              "         ...,\n",
              "         [169, 180, 188],\n",
              "         [167, 178, 186],\n",
              "         [165, 176, 184]],\n",
              " \n",
              "        [[166, 182, 194],\n",
              "         [165, 181, 193],\n",
              "         [164, 180, 192],\n",
              "         ...,\n",
              "         [168, 179, 187],\n",
              "         [168, 179, 187],\n",
              "         [168, 179, 187]],\n",
              " \n",
              "        [[166, 182, 194],\n",
              "         [165, 181, 193],\n",
              "         [164, 180, 192],\n",
              "         ...,\n",
              "         [167, 178, 186],\n",
              "         [169, 180, 188],\n",
              "         [170, 181, 189]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[119, 135, 141],\n",
              "         [120, 136, 142],\n",
              "         [129, 144, 147],\n",
              "         ...,\n",
              "         [135, 152, 165],\n",
              "         [134, 151, 164],\n",
              "         [136, 153, 166]],\n",
              " \n",
              "        [[119, 134, 137],\n",
              "         [125, 140, 143],\n",
              "         [140, 155, 158],\n",
              "         ...,\n",
              "         [135, 152, 165],\n",
              "         [136, 153, 166],\n",
              "         [141, 158, 171]],\n",
              " \n",
              "        [[126, 141, 144],\n",
              "         [134, 149, 152],\n",
              "         [151, 166, 169],\n",
              "         ...,\n",
              "         [137, 154, 167],\n",
              "         [139, 156, 169],\n",
              "         [145, 162, 175]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/p17_jpg.rf.f6b55c6ef43ac2ab295f7056a1956c86.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.8923282623291016, 'inference': 58.428287506103516, 'postprocess': 2.582550048828125},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[155, 164, 197],\n",
              "         [157, 167, 197],\n",
              "         [157, 168, 198],\n",
              "         ...,\n",
              "         [ 21,  17,  22],\n",
              "         [ 21,  17,  22],\n",
              "         [ 21,  17,  22]],\n",
              " \n",
              "        [[154, 165, 197],\n",
              "         [156, 167, 199],\n",
              "         [158, 169, 199],\n",
              "         ...,\n",
              "         [ 21,  17,  22],\n",
              "         [ 21,  17,  22],\n",
              "         [ 21,  17,  22]],\n",
              " \n",
              "        [[152, 164, 198],\n",
              "         [155, 168, 200],\n",
              "         [158, 171, 203],\n",
              "         ...,\n",
              "         [ 21,  17,  22],\n",
              "         [ 21,  17,  22],\n",
              "         [ 21,  17,  22]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[117, 143, 155],\n",
              "         [117, 143, 155],\n",
              "         [118, 144, 156],\n",
              "         ...,\n",
              "         [ 95, 107, 109],\n",
              "         [ 95, 107, 109],\n",
              "         [ 95, 107, 109]],\n",
              " \n",
              "        [[116, 143, 153],\n",
              "         [116, 143, 153],\n",
              "         [117, 144, 154],\n",
              "         ...,\n",
              "         [ 95, 107, 109],\n",
              "         [ 94, 106, 108],\n",
              "         [ 93, 105, 107]],\n",
              " \n",
              "        [[116, 143, 153],\n",
              "         [116, 143, 153],\n",
              "         [117, 144, 154],\n",
              "         ...,\n",
              "         [ 94, 106, 108],\n",
              "         [ 93, 105, 107],\n",
              "         [ 92, 104, 106]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/p24_jpg.rf.6673d6f98dc7183b869a53be3a8cc00b.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.5981197357177734, 'inference': 58.637380599975586, 'postprocess': 5.916357040405273},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[248, 247, 243],\n",
              "         [248, 247, 243],\n",
              "         [248, 247, 243],\n",
              "         ...,\n",
              "         [  9,  17,  10],\n",
              "         [ 11,  19,  12],\n",
              "         [ 12,  20,  13]],\n",
              " \n",
              "        [[248, 247, 243],\n",
              "         [248, 247, 243],\n",
              "         [248, 247, 243],\n",
              "         ...,\n",
              "         [  9,  17,  10],\n",
              "         [ 11,  19,  12],\n",
              "         [ 12,  20,  13]],\n",
              " \n",
              "        [[248, 247, 243],\n",
              "         [248, 247, 243],\n",
              "         [248, 247, 243],\n",
              "         ...,\n",
              "         [ 10,  18,  11],\n",
              "         [ 10,  18,  11],\n",
              "         [ 11,  19,  12]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 18,  30,  32],\n",
              "         [ 12,  24,  24],\n",
              "         [  8,  20,  20],\n",
              "         ...,\n",
              "         [ 99, 114, 117],\n",
              "         [  2,  15,  17],\n",
              "         [  3,  16,  18]],\n",
              " \n",
              "        [[ 22,  33,  37],\n",
              "         [ 15,  27,  29],\n",
              "         [ 10,  22,  24],\n",
              "         ...,\n",
              "         [112, 127, 130],\n",
              "         [  1,  14,  16],\n",
              "         [ 13,  25,  27]],\n",
              " \n",
              "        [[ 19,  30,  34],\n",
              "         [ 15,  26,  30],\n",
              "         [ 11,  23,  25],\n",
              "         ...,\n",
              "         [109, 124, 127],\n",
              "         [ 12,  24,  26],\n",
              "         [ 86,  98, 100]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/p28_jpg.rf.d850f345c555a878078d046bc6a014cc.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.5919208526611328, 'inference': 58.61854553222656, 'postprocess': 1.9431114196777344},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[145, 153, 152],\n",
              "         [145, 153, 152],\n",
              "         [145, 153, 152],\n",
              "         ...,\n",
              "         [109, 119, 129],\n",
              "         [109, 119, 129],\n",
              "         [109, 119, 129]],\n",
              " \n",
              "        [[145, 153, 152],\n",
              "         [145, 153, 152],\n",
              "         [145, 153, 152],\n",
              "         ...,\n",
              "         [109, 119, 129],\n",
              "         [109, 119, 129],\n",
              "         [109, 119, 129]],\n",
              " \n",
              "        [[145, 153, 152],\n",
              "         [145, 153, 152],\n",
              "         [145, 153, 152],\n",
              "         ...,\n",
              "         [109, 119, 129],\n",
              "         [109, 119, 129],\n",
              "         [109, 119, 129]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 82, 101, 122],\n",
              "         [ 86, 105, 126],\n",
              "         [ 90, 109, 130],\n",
              "         ...,\n",
              "         [ 45,  50,  53],\n",
              "         [ 45,  50,  53],\n",
              "         [ 46,  51,  54]],\n",
              " \n",
              "        [[ 76,  95, 116],\n",
              "         [ 80,  99, 120],\n",
              "         [ 85, 104, 125],\n",
              "         ...,\n",
              "         [ 44,  49,  52],\n",
              "         [ 44,  49,  52],\n",
              "         [ 44,  49,  52]],\n",
              " \n",
              "        [[ 72,  91, 112],\n",
              "         [ 75,  94, 115],\n",
              "         [ 80,  99, 120],\n",
              "         ...,\n",
              "         [ 43,  48,  51],\n",
              "         [ 43,  48,  51],\n",
              "         [ 43,  48,  51]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/p8_jpg.rf.0704f4dd7b0ec7a03ae271d4a3800d23.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.5609264373779297, 'inference': 58.30264091491699, 'postprocess': 1.7731189727783203},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[146, 146, 132],\n",
              "         [146, 146, 132],\n",
              "         [146, 146, 132],\n",
              "         ...,\n",
              "         [222, 227, 195],\n",
              "         [222, 227, 195],\n",
              "         [222, 227, 195]],\n",
              " \n",
              "        [[146, 146, 132],\n",
              "         [146, 146, 132],\n",
              "         [146, 146, 132],\n",
              "         ...,\n",
              "         [222, 227, 195],\n",
              "         [222, 227, 195],\n",
              "         [222, 227, 195]],\n",
              " \n",
              "        [[146, 146, 132],\n",
              "         [146, 146, 132],\n",
              "         [146, 146, 132],\n",
              "         ...,\n",
              "         [222, 227, 195],\n",
              "         [222, 227, 195],\n",
              "         [222, 227, 195]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[235, 238, 213],\n",
              "         [235, 238, 213],\n",
              "         [235, 238, 213],\n",
              "         ...,\n",
              "         [206, 210, 169],\n",
              "         [206, 210, 169],\n",
              "         [207, 211, 170]],\n",
              " \n",
              "        [[235, 238, 213],\n",
              "         [235, 238, 213],\n",
              "         [235, 238, 213],\n",
              "         ...,\n",
              "         [207, 211, 170],\n",
              "         [206, 210, 169],\n",
              "         [207, 211, 170]],\n",
              " \n",
              "        [[235, 238, 213],\n",
              "         [235, 238, 213],\n",
              "         [235, 238, 213],\n",
              "         ...,\n",
              "         [207, 211, 170],\n",
              "         [206, 210, 169],\n",
              "         [207, 211, 170]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/pen17_jpg.rf.b3192e012f273939dbe8937aefbe8f12.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.5954971313476562, 'inference': 58.302879333496094, 'postprocess': 1.9392967224121094},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[137, 133, 132],\n",
              "         [137, 133, 132],\n",
              "         [137, 133, 132],\n",
              "         ...,\n",
              "         [181, 176, 175],\n",
              "         [181, 176, 175],\n",
              "         [181, 176, 175]],\n",
              " \n",
              "        [[137, 133, 132],\n",
              "         [137, 133, 132],\n",
              "         [137, 133, 132],\n",
              "         ...,\n",
              "         [181, 176, 175],\n",
              "         [181, 176, 175],\n",
              "         [181, 176, 175]],\n",
              " \n",
              "        [[137, 133, 132],\n",
              "         [137, 133, 132],\n",
              "         [137, 133, 132],\n",
              "         ...,\n",
              "         [181, 176, 175],\n",
              "         [181, 176, 175],\n",
              "         [181, 176, 175]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[157, 158, 156],\n",
              "         [157, 158, 156],\n",
              "         [157, 158, 156],\n",
              "         ...,\n",
              "         [191, 189, 188],\n",
              "         [192, 190, 189],\n",
              "         [193, 191, 190]],\n",
              " \n",
              "        [[157, 158, 156],\n",
              "         [157, 158, 156],\n",
              "         [156, 157, 155],\n",
              "         ...,\n",
              "         [192, 190, 189],\n",
              "         [192, 190, 189],\n",
              "         [192, 190, 189]],\n",
              " \n",
              "        [[157, 158, 156],\n",
              "         [157, 158, 156],\n",
              "         [156, 157, 155],\n",
              "         ...,\n",
              "         [192, 190, 189],\n",
              "         [192, 190, 189],\n",
              "         [192, 190, 189]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/all_data/test/images/w3_jpg.rf.17144b2e19c862bfa26843523c374c83.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.5971660614013672, 'inference': 58.34698677062988, 'postprocess': 0.9884834289550781}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infer.predict(\"/content/drive/MyDrive/all_data/test/images\", save = True, save_txt = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uUsJFHvnq-X",
        "outputId": "5dd6c071-7231-47da-cc14-b539266f602e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "args.yaml\t\t\t\t\t    results.csv\n",
            "confusion_matrix.png\t\t\t\t    results.png\n",
            "events.out.tfevents.1682714250.f82c96539054.1703.0  train_batch0.jpg\n",
            "F1_curve.png\t\t\t\t\t    train_batch1.jpg\n",
            "labels_correlogram.jpg\t\t\t\t    train_batch2.jpg\n",
            "labels.jpg\t\t\t\t\t    val_batch0_labels.jpg\n",
            "P_curve.png\t\t\t\t\t    val_batch0_pred.jpg\n",
            "PR_curve.png\t\t\t\t\t    weights\n",
            "R_curve.png\n"
          ]
        }
      ],
      "source": [
        "!ls /content/runs/detect/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zt8kTiAoDX_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
