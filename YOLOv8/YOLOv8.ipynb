{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKB_Qtu2DcjS"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP1q424HF8_C"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8m.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PgvUWOkGFMx"
      },
      "outputs": [],
      "source": [
        "!touch data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glZvAdbTITwJ",
        "outputId": "498e8db1-2ef5-4418-8a0b-456e68fd46cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.89 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/data.yaml, epochs=25, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.Detect                [10, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25862110 parameters, 25862094 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 144MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/all_data/train/labels.cache... 186 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/all_data/valid/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/25      7.91G      1.563      4.219      1.926         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.11s/it]\n",
            "                   all         31         54      0.471      0.369      0.326      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/25      7.11G      1.497      2.645      1.874         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         31         54      0.689      0.528      0.539       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/25      7.11G      1.314      2.074      1.657         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]\n",
            "                   all         31         54      0.735      0.587      0.688      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/25      7.12G      1.234      1.824      1.592         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.68s/it]\n",
            "                   all         31         54      0.589      0.505      0.567      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/25      7.12G      1.154      1.509      1.506         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.15s/it]\n",
            "                   all         31         54      0.843      0.576      0.659       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/25       7.1G      1.093      1.315      1.467         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.07s/it]\n",
            "                   all         31         54       0.71      0.691      0.742      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/25      7.09G      1.105      1.287      1.417         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all         31         54      0.763      0.668      0.748      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/25      7.11G      1.089      1.139      1.399         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.52s/it]\n",
            "                   all         31         54      0.749      0.656      0.744      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/25       7.1G      1.098      1.122      1.398         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                   all         31         54      0.813      0.688      0.766      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/25      7.11G      1.068      1.111      1.377         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         31         54      0.789      0.636      0.729      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/25       7.1G      1.049      1.066      1.363         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                   all         31         54      0.803      0.581      0.656      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/25       7.1G     0.9819     0.9811       1.33         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]\n",
            "                   all         31         54      0.576      0.592      0.594      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/25      7.12G      1.002     0.9492      1.316         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.08s/it]\n",
            "                   all         31         54      0.654      0.663      0.646      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/25      7.11G     0.9861     0.9253      1.335         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         31         54      0.625      0.615      0.643      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/25      7.11G     0.9099     0.8538      1.261         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.02s/it]\n",
            "                   all         31         54      0.645      0.632      0.637      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/25       7.1G      0.875     0.8195      1.268         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.01s/it]\n",
            "                   all         31         54      0.752      0.568        0.6      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/25       7.1G     0.8684     0.7989      1.252         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         31         54      0.633      0.653      0.678      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/25       7.1G     0.8372     0.7448      1.232         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.05s/it]\n",
            "                   all         31         54      0.755      0.568      0.626      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/25      7.11G     0.8275     0.7119      1.225         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.04s/it]\n",
            "                   all         31         54       0.72      0.593      0.659      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/25       7.1G     0.8159     0.6732      1.195         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                   all         31         54      0.676      0.593      0.645      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/25       7.1G     0.7837     0.6921       1.18         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all         31         54      0.754      0.574       0.67      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/25       7.1G     0.7447     0.6464      1.171         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:07<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                   all         31         54      0.685       0.68      0.671      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/25      7.12G     0.7596     0.6579      1.196         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n",
            "                   all         31         54       0.75      0.609      0.678      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/25      7.12G     0.7087     0.5815       1.15         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
            "                   all         31         54      0.877      0.606      0.746      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/25       7.1G     0.6834     0.5777      1.135         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:08<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.09s/it]\n",
            "                   all         31         54      0.809      0.616      0.768       0.49\n",
            "\n",
            "25 epochs completed in 0.084 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.89 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25845550 parameters, 0 gradients, 78.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all         31         54      0.713       0.69      0.743      0.502\n",
            "                  book         31          4      0.422        0.5      0.552      0.403\n",
            "                bottle         31          5      0.814        0.4      0.508      0.319\n",
            "                   cup         31          4          1      0.913      0.995       0.62\n",
            "               glasses         31          2      0.528        0.5      0.828       0.58\n",
            "              keyboard         31          4      0.853       0.75      0.945      0.791\n",
            "                  lock         31          2      0.641          1      0.663      0.423\n",
            "                   pen         31         10      0.637        0.5       0.44      0.264\n",
            "                person         31         17          1      0.841      0.974       0.63\n",
            "            smartphone         31          4      0.649          1      0.995      0.783\n",
            "                 watch         31          2      0.589        0.5      0.528      0.206\n",
            "Speed: 0.3ms preprocess, 11.4ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model.train(data=\"/content/data.yaml\" , epochs = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmYibQbgJIpg"
      },
      "outputs": [],
      "source": [
        "infer = YOLO(\"/content/runs/detect/train3/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SZB8pgRSE4p",
        "outputId": "9457a29e-79c4-4ea1-f7b6-8deeb3139a5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/5 /content/drive/MyDrive/test_images/img_1.jpg: 448x640 3 persons, 28.5ms\n",
            "image 2/5 /content/drive/MyDrive/test_images/img_2.jpg: 448x640 1 person, 27.9ms\n",
            "image 3/5 /content/drive/MyDrive/test_images/img_4.jpg: 640x544 1 glasses, 1 person, 1 smartphone, 36.8ms\n",
            "image 4/5 /content/drive/MyDrive/test_images/img_5.jpg: 640x640 1 book, 1 glasses, 1 person, 38.0ms\n",
            "image 5/5 /content/drive/MyDrive/test_images/img_6.jpg: 640x512 1 person, 28.9ms\n",
            "Speed: 2.4ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "5 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[  1,  32,   3],\n",
              "         [ 12,  44,  13],\n",
              "         [ 56,  87,  54],\n",
              "         ...,\n",
              "         [ 70, 128, 103],\n",
              "         [ 84, 130, 117],\n",
              "         [ 87, 129, 122]],\n",
              " \n",
              "        [[ 32,  63,  34],\n",
              "         [ 17,  49,  18],\n",
              "         [ 49,  80,  47],\n",
              "         ...,\n",
              "         [ 75, 127, 103],\n",
              "         [ 92, 132, 120],\n",
              "         [126, 160, 153]],\n",
              " \n",
              "        [[ 61,  92,  63],\n",
              "         [ 24,  56,  25],\n",
              "         [ 39,  72,  38],\n",
              "         ...,\n",
              "         [ 87, 127, 102],\n",
              "         [106, 132, 119],\n",
              "         [169, 190, 182]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[107, 105,  95],\n",
              "         [113, 111, 101],\n",
              "         [134, 132, 122],\n",
              "         ...,\n",
              "         [214, 223, 226],\n",
              "         [213, 221, 228],\n",
              "         [212, 219, 228]],\n",
              " \n",
              "        [[114, 112, 104],\n",
              "         [105, 104,  94],\n",
              "         [110, 109,  99],\n",
              "         ...,\n",
              "         [212, 221, 224],\n",
              "         [212, 220, 227],\n",
              "         [211, 218, 227]],\n",
              " \n",
              "        [[126, 124, 116],\n",
              "         [122, 120, 112],\n",
              "         [128, 127, 117],\n",
              "         ...,\n",
              "         [209, 218, 221],\n",
              "         [210, 218, 225],\n",
              "         [210, 217, 226]]], dtype=uint8)\n",
              " orig_shape: (300, 446)\n",
              " path: '/content/drive/MyDrive/test_images/img_1.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 2.1054744720458984, 'inference': 28.487443923950195, 'postprocess': 1.8846988677978516},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[233, 187, 146],\n",
              "         [233, 187, 146],\n",
              "         [233, 187, 146],\n",
              "         ...,\n",
              "         [156, 134, 109],\n",
              "         [154, 132, 107],\n",
              "         [153, 131, 106]],\n",
              " \n",
              "        [[233, 187, 146],\n",
              "         [233, 187, 146],\n",
              "         [233, 187, 146],\n",
              "         ...,\n",
              "         [152, 134, 111],\n",
              "         [154, 133, 112],\n",
              "         [152, 134, 111]],\n",
              " \n",
              "        [[233, 187, 146],\n",
              "         [233, 187, 146],\n",
              "         [233, 187, 146],\n",
              "         ...,\n",
              "         [149, 135, 117],\n",
              "         [157, 141, 125],\n",
              "         [159, 145, 127]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 83,  68,  52],\n",
              "         [ 83,  68,  52],\n",
              "         [ 83,  68,  52],\n",
              "         ...,\n",
              "         [121, 130, 134],\n",
              "         [121, 130, 134],\n",
              "         [122, 131, 135]],\n",
              " \n",
              "        [[ 85,  70,  54],\n",
              "         [ 85,  70,  54],\n",
              "         [ 85,  70,  54],\n",
              "         ...,\n",
              "         [120, 129, 133],\n",
              "         [121, 130, 134],\n",
              "         [122, 131, 135]],\n",
              " \n",
              "        [[ 87,  72,  56],\n",
              "         [ 87,  72,  56],\n",
              "         [ 87,  72,  56],\n",
              "         ...,\n",
              "         [125, 134, 138],\n",
              "         [126, 135, 139],\n",
              "         [128, 137, 141]]], dtype=uint8)\n",
              " orig_shape: (440, 660)\n",
              " path: '/content/drive/MyDrive/test_images/img_2.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 1.970052719116211, 'inference': 27.858257293701172, 'postprocess': 2.0563602447509766},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[ 86, 105, 120],\n",
              "         [ 86, 105, 120],\n",
              "         [ 86, 105, 120],\n",
              "         ...,\n",
              "         [254, 253, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 255, 253]],\n",
              " \n",
              "        [[ 95, 114, 129],\n",
              "         [ 95, 114, 129],\n",
              "         [ 94, 113, 128],\n",
              "         ...,\n",
              "         [254, 253, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 255, 253]],\n",
              " \n",
              "        [[107, 126, 141],\n",
              "         [107, 126, 141],\n",
              "         [106, 125, 140],\n",
              "         ...,\n",
              "         [254, 253, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 255, 253]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[122, 168, 199],\n",
              "         [122, 168, 199],\n",
              "         [122, 168, 199],\n",
              "         ...,\n",
              "         [243, 251, 255],\n",
              "         [247, 252, 255],\n",
              "         [248, 251, 255]],\n",
              " \n",
              "        [[124, 170, 201],\n",
              "         [124, 170, 201],\n",
              "         [124, 170, 201],\n",
              "         ...,\n",
              "         [244, 252, 255],\n",
              "         [248, 253, 255],\n",
              "         [249, 252, 255]],\n",
              " \n",
              "        [[124, 170, 201],\n",
              "         [124, 170, 201],\n",
              "         [124, 170, 201],\n",
              "         ...,\n",
              "         [244, 252, 255],\n",
              "         [248, 253, 255],\n",
              "         [249, 252, 255]]], dtype=uint8)\n",
              " orig_shape: (1146, 955)\n",
              " path: '/content/drive/MyDrive/test_images/img_4.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 2.604961395263672, 'inference': 36.81683540344238, 'postprocess': 1.7273426055908203},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[206, 208, 219],\n",
              "         [206, 208, 219],\n",
              "         [206, 208, 219],\n",
              "         ...,\n",
              "         [234, 237, 242],\n",
              "         [234, 237, 242],\n",
              "         [234, 237, 242]],\n",
              " \n",
              "        [[206, 208, 219],\n",
              "         [206, 208, 219],\n",
              "         [206, 208, 219],\n",
              "         ...,\n",
              "         [234, 237, 242],\n",
              "         [234, 237, 242],\n",
              "         [234, 237, 242]],\n",
              " \n",
              "        [[206, 208, 219],\n",
              "         [206, 208, 219],\n",
              "         [206, 208, 219],\n",
              "         ...,\n",
              "         [234, 237, 242],\n",
              "         [234, 237, 242],\n",
              "         [234, 237, 242]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[158, 158, 172],\n",
              "         [158, 158, 172],\n",
              "         [158, 158, 172],\n",
              "         ...,\n",
              "         [135, 131, 150],\n",
              "         [136, 132, 151],\n",
              "         [139, 135, 154]],\n",
              " \n",
              "        [[159, 159, 173],\n",
              "         [159, 159, 173],\n",
              "         [160, 160, 174],\n",
              "         ...,\n",
              "         [136, 132, 151],\n",
              "         [137, 133, 152],\n",
              "         [141, 137, 156]],\n",
              " \n",
              "        [[160, 160, 174],\n",
              "         [160, 160, 174],\n",
              "         [160, 160, 174],\n",
              "         ...,\n",
              "         [136, 132, 151],\n",
              "         [138, 134, 153],\n",
              "         [141, 137, 156]]], dtype=uint8)\n",
              " orig_shape: (1080, 1080)\n",
              " path: '/content/drive/MyDrive/test_images/img_5.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 3.0531883239746094, 'inference': 37.98103332519531, 'postprocess': 2.5942325592041016},\n",
              " ultralytics.yolo.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.yolo.engine.results.Boxes object\n",
              " keypoints: None\n",
              " keys: ['boxes']\n",
              " masks: None\n",
              " names: {0: 'book', 1: 'bottle', 2: 'cup', 3: 'glasses', 4: 'keyboard', 5: 'lock', 6: 'pen', 7: 'person', 8: 'smartphone', 9: 'watch'}\n",
              " orig_img: array([[[  2,   0,   0],\n",
              "         [  2,   0,   0],\n",
              "         [  2,   0,   0],\n",
              "         ...,\n",
              "         [ 59,  62,  70],\n",
              "         [ 58,  61,  69],\n",
              "         [ 58,  61,  69]],\n",
              " \n",
              "        [[  2,   0,   0],\n",
              "         [  3,   1,   1],\n",
              "         [  3,   1,   1],\n",
              "         ...,\n",
              "         [ 56,  59,  67],\n",
              "         [ 57,  59,  67],\n",
              "         [ 56,  59,  67]],\n",
              " \n",
              "        [[  3,   1,   1],\n",
              "         [  3,   1,   1],\n",
              "         [  3,   1,   1],\n",
              "         ...,\n",
              "         [ 59,  60,  70],\n",
              "         [ 61,  60,  70],\n",
              "         [ 58,  59,  69]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  3,   0,   2],\n",
              "         [  3,   5,   6],\n",
              "         [123, 131, 131],\n",
              "         ...,\n",
              "         [163, 196, 216],\n",
              "         [164, 197, 217],\n",
              "         [163, 196, 216]],\n",
              " \n",
              "        [[  2,   0,   1],\n",
              "         [  0,   0,   1],\n",
              "         [ 69,  77,  77],\n",
              "         ...,\n",
              "         [160, 193, 213],\n",
              "         [161, 194, 214],\n",
              "         [161, 194, 214]],\n",
              " \n",
              "        [[  5,   3,   3],\n",
              "         [  0,   0,   0],\n",
              "         [  7,  15,  15],\n",
              "         ...,\n",
              "         [158, 191, 211],\n",
              "         [160, 193, 213],\n",
              "         [160, 193, 213]]], dtype=uint8)\n",
              " orig_shape: (781, 622)\n",
              " path: '/content/drive/MyDrive/test_images/img_6.jpg'\n",
              " probs: None\n",
              " speed: {'preprocess': 2.3789405822753906, 'inference': 28.893470764160156, 'postprocess': 1.8498897552490234}]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "infer.predict(\"/content/drive/MyDrive/test_images\", save = True, save_txt = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3LngttVY29m",
        "outputId": "0a5be983-e9f3-4bfe-91e4-3048649e80e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "args.yaml\t\t\t\t\t   results.csv\n",
            "confusion_matrix.png\t\t\t\t   results.png\n",
            "events.out.tfevents.1682708486.1ea93f81bb82.210.1  train_batch0.jpg\n",
            "F1_curve.png\t\t\t\t\t   train_batch1.jpg\n",
            "labels_correlogram.jpg\t\t\t\t   train_batch2.jpg\n",
            "labels.jpg\t\t\t\t\t   val_batch0_labels.jpg\n",
            "P_curve.png\t\t\t\t\t   val_batch0_pred.jpg\n",
            "PR_curve.png\t\t\t\t\t   weights\n",
            "R_curve.png\n"
          ]
        }
      ],
      "source": [
        "!ls /content/runs/detect/train3"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
